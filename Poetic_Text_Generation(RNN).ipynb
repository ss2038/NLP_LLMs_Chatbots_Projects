{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCDmmCV5ihPa"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaIbmnQXi6uA",
        "outputId": "b7db7ae9-4238-4e10-e689-74d69e790f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
        "text = text[300000:800000]"
      ],
      "metadata": {
        "id": "UYNsh12wjP4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "characters = sorted(set(text))\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))"
      ],
      "metadata": {
        "id": "YDzqItn3jeZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 40\n",
        "step_size = 3"
      ],
      "metadata": {
        "id": "C2a0z2dPjh2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "next_cahracters = []\n",
        "\n",
        "for i in range(0, len(text) - seq_length, step_size):\n",
        "  sentences.append(text[i: i+seq_length])\n",
        "  next_cahracters.append(text[i+seq_length])"
      ],
      "metadata": {
        "id": "zwv5KIgAj4Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), seq_length, len(characters)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(characters)), dtype = np.bool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe1KJj8bkTFH",
        "outputId": "81f6c3c3-a7ee-42a4-861f-72cff51e98fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-1ce032c4932b>:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sentences), len(characters)), dtype = np.bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(sentences):\n",
        "  for t, character in enumerate(sentence):\n",
        "    x[i, t, char_to_index[character]] = 1\n",
        "  y[i, char_to_index[next_cahracters[i]]] = 1"
      ],
      "metadata": {
        "id": "OqZweu1NlZ83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape= (seq_length, len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "cub0-ghxmp0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy' , optimizer=RMSprop(learning_rate=0.01))\n",
        "model.fit(x, y, batch_size=256, epochs = 4)\n",
        "model.save('textgenerator.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taG3Rl4WoiKb",
        "outputId": "5d7c8d15-3728-42ba-dd93-2a993ab92010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "651/651 [==============================] - 125s 189ms/step - loss: 2.1724\n",
            "Epoch 2/4\n",
            "651/651 [==============================] - 118s 181ms/step - loss: 1.7290\n",
            "Epoch 3/4\n",
            "651/651 [==============================] - 118s 181ms/step - loss: 1.6046\n",
            "Epoch 4/4\n",
            "651/651 [==============================] - 118s 181ms/step - loss: 1.5337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/textgenerator.model')"
      ],
      "metadata": {
        "id": "VRwAIKA7pAn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "metadata": {
        "id": "49xVTrOFs8XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, temperature):\n",
        "  start_index = random.randint(0, len(text)-seq_length-1)\n",
        "  generated = ''\n",
        "  sentence = text[start_index: start_index + seq_length]\n",
        "  generated += sentence\n",
        "  for i in range(length):\n",
        "    x = np.zeros((1, seq_length, len(characters)))\n",
        "    for t, character in enumerate(sentence):\n",
        "      x[0, t, char_to_index[character]] = 1\n",
        "\n",
        "    predictions = model.predict(x, verbose=0)[0]\n",
        "    next_index = sample(predictions, temperature)\n",
        "    next_character = index_to_char[next_index]\n",
        "\n",
        "    generated += next_character\n",
        "    sentence = sentence[1:] + next_character\n",
        "  return generated"
      ],
      "metadata": {
        "id": "F9PJkzeVvzta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.1))\n",
        "print(generate_text(300, 0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC23Gml5u4ML",
        "outputId": "f572ce6b-89c7-49f0-9301-071cc3f4cfa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d:\n",
            "why, then 'tis time to arm and give death,\n",
            "and thou wast the care and the care and the hands\n",
            "the care and the worse and the care and the hands\n",
            "the care and the bear the earth the hands.\n",
            "\n",
            "clown:\n",
            "i will the earth the hands and the fierd\n",
            "the care and the breast the care and the worsent with the hands\n",
            "and what show the hand and the care th\n",
            " shall intend to do,\n",
            "by heaven, i will the cheek the care and still me.\n",
            "\n",
            "polixenes:\n",
            "i have a treess of the bear the hands thee,\n",
            "which see his his hands and the cheer and the care\n",
            "the hand the earth of the care and be some\n",
            "should not the care i shall be not the chark.\n",
            "\n",
            "warwick:\n",
            "which see him his hands the care and so still him shall\n",
            "with t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jGoxuZ5nvTLW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}